{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e6619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddhakiran/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# keras module for building LSTM (from TensorFlow)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils as ku \n",
    "\n",
    "# set seeds for reproducibility\n",
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "set_seed(2)  # Use set_seed in TensorFlow\n",
    "seed(1)\n",
    "\n",
    "# Other imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014ac1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv('ArticlesApril2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f3d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>By STEPHEN HILTNER and SUSAN LEHMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>Finding an Expansive View  of a Forgotten Peop...</td>\n",
       "      <td>['Photography', 'New York Times', 'Niger', 'Fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>Insider</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-01 00:15:41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>One of the largest photo displays in Times his...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/insider/nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>By GAIL COLLINS</td>\n",
       "      <td>article</td>\n",
       "      <td>And Now,  the Dreaded Trump Curse</td>\n",
       "      <td>['United States Politics and Government', 'Tru...</td>\n",
       "      <td>3</td>\n",
       "      <td>OpEd</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-04-01 00:23:58</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Meet the gang from under the bus.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Op-Ed</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>By THE EDITORIAL BOARD</td>\n",
       "      <td>article</td>\n",
       "      <td>Venezuela’s Descent Into Dictatorship</td>\n",
       "      <td>['Venezuela', 'Politics and Government', 'Madu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-04-01 00:53:06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A court ruling annulling the legislature’s aut...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>By MICHAEL POWELL</td>\n",
       "      <td>article</td>\n",
       "      <td>Stain Permeates Basketball Blue Blood</td>\n",
       "      <td>['Basketball (College)', 'University of North ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-01 01:06:52</td>\n",
       "      <td>College Basketball</td>\n",
       "      <td>For two decades, until 2013, North Carolina en...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/sports/ncaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>By DEB AMLEN</td>\n",
       "      <td>article</td>\n",
       "      <td>Taking Things for Granted</td>\n",
       "      <td>['Crossword Puzzles']</td>\n",
       "      <td>3</td>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-01 02:00:14</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In which Howard Barkin and Will Shortz teach u...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/crosswords/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58fd41ab7c459f24986dbaa7</td>\n",
       "      <td>710</td>\n",
       "      <td>By ANDREW E. KRAMER</td>\n",
       "      <td>article</td>\n",
       "      <td>Reporting on Gays Who ‘Don’t Exist’</td>\n",
       "      <td>['Chechnya (Russia)', 'Homosexuality and Bisex...</td>\n",
       "      <td>3</td>\n",
       "      <td>Insider</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-24 00:07:04</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>“I see flies, I see mosquitoes,” said a Cheche...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/04/23/insider/rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58fd45a17c459f24986dbaaa</td>\n",
       "      <td>1230</td>\n",
       "      <td>By MATT FLEGENHEIMER and THOMAS KAPLAN</td>\n",
       "      <td>article</td>\n",
       "      <td>The Fights That Could Lead to a Government Shu...</td>\n",
       "      <td>['Trump, Donald J', 'United States Politics an...</td>\n",
       "      <td>3</td>\n",
       "      <td>National</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-24 00:23:53</td>\n",
       "      <td>Politics</td>\n",
       "      <td>The Trump administration wants to use the dead...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/04/23/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58fd5c2c7c459f24986dbac3</td>\n",
       "      <td>1424</td>\n",
       "      <td>By NOEL MURRAY</td>\n",
       "      <td>article</td>\n",
       "      <td>‘The Leftovers’ Season 3, Episode 2: Swedish P...</td>\n",
       "      <td>['Television', 'The Leftovers (TV Program)']</td>\n",
       "      <td>3</td>\n",
       "      <td>Culture</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24 02:00:04</td>\n",
       "      <td>Television</td>\n",
       "      <td>For all its melancholy, “The Leftovers” rarely...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Review</td>\n",
       "      <td>https://www.nytimes.com/2017/04/23/arts/televi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58fd5c3d7c459f24986dbac4</td>\n",
       "      <td>1052</td>\n",
       "      <td>By BEN BRANTLEY</td>\n",
       "      <td>article</td>\n",
       "      <td>Thinking Out Loud, But Why?</td>\n",
       "      <td>['Theater', 'The Antipodes (Play)', 'Baker, An...</td>\n",
       "      <td>3</td>\n",
       "      <td>Culture</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-24 02:00:25</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In this endlessly fascinating work, Annie Bake...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Review</td>\n",
       "      <td>https://www.nytimes.com/2017/04/23/theater/the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58fd5c3d7c459f24986dbac5</td>\n",
       "      <td>981</td>\n",
       "      <td>By BEN BRANTLEY</td>\n",
       "      <td>article</td>\n",
       "      <td>Some Sugar. Could Use More Spice.</td>\n",
       "      <td>['Theater', 'Charlie and the Chocolate Factory...</td>\n",
       "      <td>3</td>\n",
       "      <td>Culture</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-24 02:00:26</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Christian Borle is the eccentric Willy Wonka i...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Review</td>\n",
       "      <td>https://www.nytimes.com/2017/04/23/theater/cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>886 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstract                 articleID  articleWordCount  \\\n",
       "0        NaN  58def1347c459f24986d7c80               716   \n",
       "1        NaN  58def3237c459f24986d7c84               823   \n",
       "2        NaN  58def9f57c459f24986d7c90               575   \n",
       "3        NaN  58defd317c459f24986d7c95              1374   \n",
       "4        NaN  58df09b77c459f24986d7ca7               708   \n",
       "..       ...                       ...               ...   \n",
       "881      NaN  58fd41ab7c459f24986dbaa7               710   \n",
       "882      NaN  58fd45a17c459f24986dbaaa              1230   \n",
       "883      NaN  58fd5c2c7c459f24986dbac3              1424   \n",
       "884      NaN  58fd5c3d7c459f24986dbac4              1052   \n",
       "885      NaN  58fd5c3d7c459f24986dbac5               981   \n",
       "\n",
       "                                     byline documentType  \\\n",
       "0       By STEPHEN HILTNER and SUSAN LEHMAN      article   \n",
       "1                           By GAIL COLLINS      article   \n",
       "2                    By THE EDITORIAL BOARD      article   \n",
       "3                         By MICHAEL POWELL      article   \n",
       "4                              By DEB AMLEN      article   \n",
       "..                                      ...          ...   \n",
       "881                     By ANDREW E. KRAMER      article   \n",
       "882  By MATT FLEGENHEIMER and THOMAS KAPLAN      article   \n",
       "883                          By NOEL MURRAY      article   \n",
       "884                         By BEN BRANTLEY      article   \n",
       "885                         By BEN BRANTLEY      article   \n",
       "\n",
       "                                              headline  \\\n",
       "0    Finding an Expansive View  of a Forgotten Peop...   \n",
       "1                    And Now,  the Dreaded Trump Curse   \n",
       "2                Venezuela’s Descent Into Dictatorship   \n",
       "3                Stain Permeates Basketball Blue Blood   \n",
       "4                            Taking Things for Granted   \n",
       "..                                                 ...   \n",
       "881                Reporting on Gays Who ‘Don’t Exist’   \n",
       "882  The Fights That Could Lead to a Government Shu...   \n",
       "883  ‘The Leftovers’ Season 3, Episode 2: Swedish P...   \n",
       "884                        Thinking Out Loud, But Why?   \n",
       "885                  Some Sugar. Could Use More Spice.   \n",
       "\n",
       "                                              keywords  multimedia    newDesk  \\\n",
       "0    ['Photography', 'New York Times', 'Niger', 'Fe...           3    Insider   \n",
       "1    ['United States Politics and Government', 'Tru...           3       OpEd   \n",
       "2    ['Venezuela', 'Politics and Government', 'Madu...           3  Editorial   \n",
       "3    ['Basketball (College)', 'University of North ...           3     Sports   \n",
       "4                                ['Crossword Puzzles']           3      Games   \n",
       "..                                                 ...         ...        ...   \n",
       "881  ['Chechnya (Russia)', 'Homosexuality and Bisex...           3    Insider   \n",
       "882  ['Trump, Donald J', 'United States Politics an...           3   National   \n",
       "883       ['Television', 'The Leftovers (TV Program)']           3    Culture   \n",
       "884  ['Theater', 'The Antipodes (Play)', 'Baker, An...           3    Culture   \n",
       "885  ['Theater', 'Charlie and the Chocolate Factory...           3    Culture   \n",
       "\n",
       "     printPage              pubDate         sectionName  \\\n",
       "0            2  2017-04-01 00:15:41             Unknown   \n",
       "1           23  2017-04-01 00:23:58             Unknown   \n",
       "2           22  2017-04-01 00:53:06             Unknown   \n",
       "3            1  2017-04-01 01:06:52  College Basketball   \n",
       "4            0  2017-04-01 02:00:14             Unknown   \n",
       "..         ...                  ...                 ...   \n",
       "881          2  2017-04-24 00:07:04             Unknown   \n",
       "882         15  2017-04-24 00:23:53            Politics   \n",
       "883          0  2017-04-24 02:00:04          Television   \n",
       "884          1  2017-04-24 02:00:25             Unknown   \n",
       "885          2  2017-04-24 02:00:26             Unknown   \n",
       "\n",
       "                                               snippet              source  \\\n",
       "0    One of the largest photo displays in Times his...  The New York Times   \n",
       "1                    Meet the gang from under the bus.  The New York Times   \n",
       "2    A court ruling annulling the legislature’s aut...  The New York Times   \n",
       "3    For two decades, until 2013, North Carolina en...  The New York Times   \n",
       "4    In which Howard Barkin and Will Shortz teach u...  The New York Times   \n",
       "..                                                 ...                 ...   \n",
       "881  “I see flies, I see mosquitoes,” said a Cheche...  The New York Times   \n",
       "882  The Trump administration wants to use the dead...  The New York Times   \n",
       "883  For all its melancholy, “The Leftovers” rarely...  The New York Times   \n",
       "884  In this endlessly fascinating work, Annie Bake...  The New York Times   \n",
       "885  Christian Borle is the eccentric Willy Wonka i...  The New York Times   \n",
       "\n",
       "    typeOfMaterial                                             webURL  \n",
       "0             News  https://www.nytimes.com/2017/03/31/insider/nig...  \n",
       "1            Op-Ed  https://www.nytimes.com/2017/03/31/opinion/and...  \n",
       "2        Editorial  https://www.nytimes.com/2017/03/31/opinion/ven...  \n",
       "3             News  https://www.nytimes.com/2017/03/31/sports/ncaa...  \n",
       "4             News  https://www.nytimes.com/2017/03/31/crosswords/...  \n",
       "..             ...                                                ...  \n",
       "881           News  https://www.nytimes.com/2017/04/23/insider/rus...  \n",
       "882           News  https://www.nytimes.com/2017/04/23/us/politics...  \n",
       "883         Review  https://www.nytimes.com/2017/04/23/arts/televi...  \n",
       "884         Review  https://www.nytimes.com/2017/04/23/theater/the...  \n",
       "885         Review  https://www.nytimes.com/2017/04/23/theater/cha...  \n",
       "\n",
       "[886 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc30e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame containing the loaded CSV file\n",
    "all_headlines = list(data.headline.values)\n",
    "\n",
    "# Filter out \"Unknown\" headlines\n",
    "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
    "\n",
    "# Output the length of valid headlines\n",
    "print(len(all_headlines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff89cf",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d7255",
   "metadata": {},
   "source": [
    "## Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ac8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finding an expansive view  of a forgotten people in niger',\n",
       " 'and now  the dreaded trump curse',\n",
       " 'venezuelas descent into dictatorship',\n",
       " 'stain permeates basketball blue blood',\n",
       " 'taking things for granted',\n",
       " 'the caged beast awakens',\n",
       " 'an everunfolding story',\n",
       " 'oreilly thrives as settlements add up',\n",
       " 'mouse infestation',\n",
       " 'divide in gop now threatens trump tax plan']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in all_headlines]\n",
    "corpus[:10]\n",
    "\n",
    "#This chunk effectively preprocesses the headlines for further analysis by normalizing the text format and removing unwanted characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1d723",
   "metadata": {},
   "source": [
    "## Generating Sequence of N-gram Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae7ee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[169, 17],\n",
       " [169, 17, 665],\n",
       " [169, 17, 665, 367],\n",
       " [169, 17, 665, 367, 4],\n",
       " [169, 17, 665, 367, 4, 2],\n",
       " [169, 17, 665, 367, 4, 2, 666],\n",
       " [169, 17, 665, 367, 4, 2, 666, 170],\n",
       " [169, 17, 665, 367, 4, 2, 666, 170, 5],\n",
       " [169, 17, 665, 367, 4, 2, 666, 170, 5, 667],\n",
       " [6, 80]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]\n",
    "\n",
    "\n",
    "#Tokenization is a process of extracting tokens(words) from a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2356e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "\n",
    "\n",
    "#This function takes a list of sequences, pads them to the same length, splits them into predictors (all tokens but the last) and the labels (last token), and converts the labels into one-hot encoded vectors. The returned values are then used for training models, typically for sequence prediction tasks like language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f4d4e",
   "metadata": {},
   "source": [
    "## LSTM's for Text Generation\n",
    "\n",
    "Input Layer : Takes the sequence of words as input\n",
    "LSTM Layer : Computes the output using LSTM units. I have added 100 units in the layer, but this number can be fine tuned later.\n",
    "Dropout Layer : A regularisation layer which randomly turns-off the activations of some neurons in the LSTM layer. It helps in preventing over fitting. (Optional Layer)\n",
    "Output Layer : Computes the probability of the best possible next word as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input Layer : Takes the sequence of words as input\n",
    "LSTM Layer : Computes the output using LSTM units. I have added 100 units in the layer, but this number can be fine tuned later.\n",
    "Dropout Layer : A regularisation layer which randomly turns-off the activations of some neurons in the LSTM layer. It helps in preventing over fitting. (Optional Layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279baf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d7abf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x323219810>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model now\n",
    "\n",
    "model.fit(predictors, label, epochs=100, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d9d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Text\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fca006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        \n",
    "        # Use model.predict() instead of predict_classes()\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        \n",
    "        # Get the class with the highest probability\n",
    "        predicted_class = np.argmax(predicted, axis=-1)\n",
    "        \n",
    "        # Find the word associated with the predicted class\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_class:\n",
    "                output_word = word\n",
    "                break\n",
    "        \n",
    "        # Add the predicted word to the seed text\n",
    "        seed_text += \" \" + output_word\n",
    "\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae3ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "united states ended about a belated budget\n",
      "president trump today a belated budget\n",
      "donald trump just a natural killer\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"united states\", 5, model, max_sequence_len, tokenizer))\n",
    "print(generate_text(\"president trump\", 4, model, max_sequence_len, tokenizer))\n",
    "print(generate_text(\"donald trump\", 4, model, max_sequence_len, tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08661344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
